{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers as tfl\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow_addons.image import transform as H_transform\n",
    "import matplotlib.pyplot as plt\n",
    "import os, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/root/Internship-Valeo/Project/data/COCO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.utils import pipeline\n",
    "from datasets.utils.pipeline import parse_primitives\n",
    "from datasets.utils import photometric_augmentation as photaug\n",
    "from models.homographies import (sample_homography, compute_valid_mask,\n",
    "                                            warp_points, filter_points)\n",
    "from models.utils import box_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "            'primitives': 'all',\n",
    "            'validation_size': 192,\n",
    "            'cache_in_memory': False,\n",
    "            'augmentation': {\n",
    "                'photometric': {\n",
    "                    'enable': True,\n",
    "                    'primitives': [\n",
    "                'random_brightness', 'random_contrast', 'additive_speckle_noise',\n",
    "                'additive_gaussian_noise', 'additive_shade', 'motion_blur' ],\n",
    "                    'params': {\n",
    "                        'random_brightness': {'max_abs_change': 50},\n",
    "                        'random_contrast': {'strength_range': [0.3, 1.5]},\n",
    "                        'additive_gaussian_noise': {'stddev_range': [0, 10]},\n",
    "                        'additive_speckle_noise': {'prob_range': [0, 0.0035]},\n",
    "                        'additive_shade':{\n",
    "                            'transparency_range': [-0.5, 0.5],\n",
    "                            'kernel_size_range': [100, 150]},\n",
    "                        'motion_blur': {'max_kernel_size': 3}},\n",
    "                    'random_order': True,\n",
    "                },\n",
    "                'homographic': {\n",
    "                    'enable': True,\n",
    "                    'params': {\n",
    "                        'translation': True,\n",
    "                        'rotation': True,\n",
    "                        'scaling': True,\n",
    "                        'perspective': True,\n",
    "                        'scaling_amplitude': 0.2,\n",
    "                        'perspective_amplitude_x': 0.2,\n",
    "                        'perspective_amplitude_y': 0.2,\n",
    "                        'patch_ratio': 0.85,\n",
    "                        'max_angle': 1.57,  # 3.14\n",
    "                        'allow_artifacts': True,\n",
    "                        'valid_border_margin': 3,\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs/scalars/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for photometric augmentation\n",
    "\n",
    "primitives_photo = parse_primitives(config['primitives'], photaug.augmentations)\n",
    "\n",
    "prim_configs = [config['augmentation']['photometric']['params'].get(p, {}) for p in primitives_photo]\n",
    "\n",
    "indices = tf.range(len(primitives_photo))\n",
    "if config['augmentation']['photometric']['random_order']:\n",
    "    indices = tf.random.shuffle(indices)\n",
    "def photo_aug_step(i, image):\n",
    "    fn_pairs = [(tf.equal(indices[i], j), lambda p=p, c=c: getattr(photaug, p)(image, **c))\n",
    "                for j, (p, c) in enumerate(zip(primitives_photo, prim_configs))]\n",
    "    image = tf.case(fn_pairs)\n",
    "    return i + 1, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read keypoints\n",
    "def _read_points(filename):\n",
    "    return np.load(filename)#.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "            'data_format': 'channels_last',\n",
    "            'grid_size': 8,\n",
    "            'detection_threshold': 0.001, # 1/65, 0.015\n",
    "            'descriptor_size': 256,\n",
    "            'batch_size': 32,\n",
    "            'eval_batch_size': 32,\n",
    "            'epochs': 25,\n",
    "            'learning_rate': 0.001,\n",
    "            'kernel_reg': 0.,\n",
    "            'lambda_d': 250,\n",
    "            'descriptor_size': 256,\n",
    "            'positive_margin': 1,\n",
    "            'negative_margin': 0.2,\n",
    "            'lambda_loss': 0.0001,\n",
    "            'nms': 4,\n",
    "            'top_k': 0,\n",
    "            # top_k: 300\n",
    "            'train_iter': 18000,\n",
    "            'validation_interval': 1000\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGen(keras.utils.Sequence):\n",
    "    def __init__(self, image_path, point_path, #homography_path, warped_image_path, warped_point_path,\n",
    "                 is_training, batch_size = model_config['batch_size']):\n",
    "        self.__ids = os.listdir(image_path)\n",
    "        self.__image_path, self.__point_path = image_path, point_path\n",
    "        \n",
    "        \n",
    "#         self.__homography_path = homography_path\n",
    "#         self.__warped_image_path = warped_image_path\n",
    "#         self.__warped_point_path = warped_point_path\n",
    "        \n",
    "        \n",
    "        self.__batch_size = batch_size\n",
    "        self.__is_training = is_training\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __load__(self , id_name):\n",
    "    \n",
    "        image_path = os.path.join(self.__image_path , id_name)\n",
    "        point_path = os.path.join(self.__point_path , id_name) + '.npy'\n",
    "    \n",
    "        image = cv2.imread(image_path , 0) # 0 specifies GreyScale format\n",
    "        image = cv2.resize(image , (320 , 240)) # resizing before inserting to the network\n",
    "        image = np.expand_dims(image, axis = 2)\n",
    "        \n",
    "        points = _read_points(point_path)\n",
    "#         points = np.round(points).astype(int)\n",
    "    \n",
    "        return image , points\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        images = []\n",
    "        points_maps = []\n",
    "        points_list = []\n",
    "        homography_list = [] # not returned yet\n",
    "        warped_images = []\n",
    "        valid_masks = []\n",
    "        warped_points_list = []\n",
    "        warped_points_maps = []\n",
    "        \n",
    "        \n",
    "        if (index + 1)*self.__batch_size > len(self.__ids):\n",
    "            self.__batch_size = len(self.__ids) - index * self.__batch_size\n",
    "        file_batch = self.__ids[index * self.__batch_size : (index + 1) * self.__batch_size]    \n",
    "        \n",
    "        for id_name in file_batch:\n",
    "            image, points = self.__load__(id_name)\n",
    "            image_shape = tf.shape(image)[:2]\n",
    "\n",
    "            \n",
    "#             homography_file = os.path.join(self.__homography_path, id_name) + '.npy'\n",
    "#             homography = _read_points(homography_file)\n",
    "#             warped_img_file = os.path.join(self.__warped_image_path, id_name)\n",
    "#             warped_image = cv2.imread(warped_img_file, 0)\n",
    "#             warped_image = np.expand_dims(warped_image, axis = 2)\n",
    "#             warped_point_file = os.path.join(self.__warped_point_path, id_name) + '.npy'\n",
    "#             warped_points = _read_points(warped_point_file)\n",
    "            \n",
    "    \n",
    "            if self.__is_training:\n",
    "                # add photometric_augmentation\n",
    "                _, image = tf.while_loop(lambda i, image: tf.less(i, len(primitives_photo)),\n",
    "                                 photo_aug_step, [0, image], parallel_iterations=1)              \n",
    "                \n",
    "                # add homography\n",
    "                homography = sample_homography(image_shape, config['augmentation']['homographic']['params'])[0]\n",
    "                warped_image = H_transform(image, homography, interpolation='BILINEAR')\n",
    "                valid_mask = compute_valid_mask(image_shape, homography,\n",
    "                                         config['augmentation']['homographic']['params']['valid_border_margin'])\n",
    "                warped_points = warp_points(points, homography)\n",
    "                warped_points = filter_points(warped_points, image_shape)\n",
    "                warped_points = np.round(warped_points).astype(int)\n",
    "                warped_kp = tf.minimum(warped_points, image_shape-1)\n",
    "                warped_points_map = tf.scatter_nd(warped_points, tf.ones([tf.shape(warped_points)[0]], \n",
    "                                                                     dtype=tf.int32), image_shape)\n",
    "                        \n",
    "                homography_list.append(homography)\n",
    "                warped_image = warped_image / 255.0\n",
    "                warped_images.append(warped_image)\n",
    "                valid_masks.append(valid_mask)\n",
    "                warped_points_list.append(warped_points)\n",
    "                warped_points_maps.append(warped_points_map)\n",
    "\n",
    "            kp = tf.minimum(points, image_shape-1)\n",
    "            points_map = tf.scatter_nd(kp, tf.ones([tf.shape(kp)[0]], dtype=tf.int32), image_shape)\n",
    "            \n",
    "            image = image / 255.0\n",
    "            images.append(image)\n",
    "            points_maps.append(points_map)\n",
    "            points_list.append(points)\n",
    "            \n",
    "            \n",
    "        images = np.array(images)\n",
    "        points_maps = np.expand_dims(points_maps, axis = 3)\n",
    "        points_maps = np.array(points_maps)\n",
    "        if self.__is_training:\n",
    "            warped_images = np.array(warped_images)\n",
    "            warped_points_maps = np.expand_dims(warped_points_maps, axis = 3)\n",
    "            warped_points_maps = np.array(warped_points_maps)\n",
    "            valid_masks = np.array(valid_masks)\n",
    "            dummy_loss_target = np.zeros(self.__batch_size)\n",
    "\n",
    "            return [warped_images, valid_masks, warped_points_maps], [dummy_loss_target]\n",
    "        \n",
    "        else:\n",
    "            return images, points_maps   \n",
    "           \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.__ids) / float(self.__batch_size)))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(inputs, filters, kernel_size, name, data_format, training=False,\n",
    "              batch_normalization=True, kernel_reg=0., **params):\n",
    "    x = tfl.Convolution2D(filters, kernel_size, kernel_initializer='he_uniform',\n",
    "                       kernel_regularizer=tf.keras.regularizers.L2(kernel_reg),\n",
    "                       data_format=data_format, **params)(inputs)\n",
    "    if batch_normalization:\n",
    "        x = tfl.BatchNormalization(\n",
    "                    fused=True,\n",
    "                    axis=1 if data_format == 'channels_first' else -1)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shared_encoder(inputs, model_config):\n",
    "    params_conv = {'padding': 'SAME', 'data_format': model_config['data_format'],\n",
    "                   'batch_normalization': True,\n",
    "                   'kernel_reg': model_config.get('kernel_reg', 0.)}\n",
    "    cfirst = model_config['data_format'] == 'channels_first'\n",
    "    cindex = 1 if cfirst else -1  # index of the channel\n",
    "    pool_size=(2, 2)\n",
    "    kernel = 3\n",
    "    # Encoder\n",
    "    conv1 = vgg_block(inputs, 64, (kernel, kernel), 'conv1_1', **params_conv)\n",
    "    conv2 = vgg_block(conv1, 64, (kernel, kernel), 'conv1_2', **params_conv)\n",
    "    pool1 = MaxPooling2D(pool_size, name=\"block1_pool\")(conv2)\n",
    "\n",
    "    conv3 = vgg_block(pool1, 64, (kernel, kernel), 'conv2_1', **params_conv)\n",
    "    conv4 = vgg_block(conv3, 64, (kernel, kernel), 'conv2_2', **params_conv)\n",
    "    pool2 = MaxPooling2D(pool_size, name=\"block2_pool\")(conv4)\n",
    "\n",
    "    conv5 = vgg_block(pool2, 128, (kernel, kernel), 'conv3_1', **params_conv)\n",
    "    conv6 = vgg_block(conv5, 128, (kernel, kernel), 'conv3_2', **params_conv)\n",
    "    pool3 = MaxPooling2D(pool_size, name=\"block3_pool\")(conv6)\n",
    "\n",
    "    conv7 = vgg_block(pool3, 128, (kernel, kernel), 'conv4_1', **params_conv)\n",
    "    conv8 = vgg_block(conv7, 128, (kernel, kernel), 'conv4_2', **params_conv)\n",
    "    return conv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detector_head(inputs, model_config):\n",
    "    params_conv = {'padding': 'SAME', 'data_format': model_config['data_format'],\n",
    "                   'batch_normalization': True,\n",
    "                   'kernel_reg': model_config.get('kernel_reg', 0.)}\n",
    "    cfirst = model_config['data_format'] == 'channels_first'\n",
    "    cindex = 1 if cfirst else -1  # index of the channel\n",
    "\n",
    "    x = vgg_block(inputs, 256, 3, 'conv1',\n",
    "                      activation=tf.nn.relu, **params_conv)\n",
    "    x = vgg_block(x, 1+pow(model_config['grid_size'], 2), 1, 'conv2',\n",
    "                      activation=None, **params_conv)\n",
    "\n",
    "    prob = tf.nn.softmax(x, axis=cindex)\n",
    "    # Strip the extra “no interest point” dustbin\n",
    "    prob = prob[:, :-1, :, :] if cfirst else prob[:, :, :, :-1]\n",
    "    prob = tf.nn.depth_to_space(\n",
    "              prob, model_config['grid_size'], data_format='NCHW' if cfirst else 'NHWC')\n",
    "    prob = tf.squeeze(prob, axis=cindex)\n",
    "    return {'logits': x, 'prob': prob}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detector_loss(keypoint_map, logits, model_config, valid_mask=None):\n",
    "    if model_config['data_format'] == 'channels_first':\n",
    "        logits = tf.transpose(logits, [0, 2, 3, 1])\n",
    "    # Convert the boolean labels to indices including the \"no interest point\" dustbin\n",
    "    labels = keypoint_map#[..., tf.newaxis]  # for GPU\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    labels = tf.nn.space_to_depth(labels, model_config['grid_size'])\n",
    "    shape = tf.concat([tf.shape(labels)[:3], [1]], axis=0)\n",
    "    labels = tf.concat([2*labels, tf.ones(shape)], 3)\n",
    "    # Add a small random matrix to randomly break ties in argmax\n",
    "    labels = tf.argmax(labels + tf.random.uniform(tf.shape(labels), 0, 0.1), axis=3)\n",
    "    # Mask the pixels if bordering artifacts appear\n",
    "    valid_mask = tf.ones_like(keypoint_map) if valid_mask is None else valid_mask\n",
    "#     valid_mask = valid_mask[..., tf.newaxis]  # for GPU\n",
    "    valid_mask = tf.cast(valid_mask, tf.float32)\n",
    "    valid_mask = tf.nn.space_to_depth(valid_mask, model_config['grid_size'])\n",
    "    valid_mask = tf.math.reduce_prod(valid_mask, axis=3)  # AND along the channel dim\n",
    "    valid_mask = tf.cast(valid_mask, tf.int64)\n",
    "#     labels = labels * valid_mask\n",
    "#     loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "    loss = tf.compat.v1.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits, weights=valid_mask)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_metrics(y_true, y_pred, valid_mask):\n",
    "    if model_config['nms']:\n",
    "        prob = tf.map_fn(lambda p: box_nms(p, model_config['nms'],\n",
    "                                               min_prob=model_config['detection_threshold'],\n",
    "                                               keep_top_k=model_config['top_k']), y_pred)\n",
    "    pred = tf.cast(tf.greater_equal(prob, model_config['detection_threshold']), tf.float32)\n",
    "    pred = tf.expand_dims(pred, axis = 3)\n",
    "    pred = valid_mask * pred\n",
    "    labels = y_true\n",
    "    precision = tf.math.reduce_sum(pred * labels) / tf.math.reduce_sum(pred)\n",
    "    recall = tf.math.reduce_sum(pred * labels) / tf.math.reduce_sum(labels)\n",
    "#     return {'precision': precision, 'recall': recall}\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectorLossLayer(Layer):\n",
    "    def __init__(self, name='detector_loss_layer', trainable=False):\n",
    "        super(DetectorLossLayer, self).__init__(name=name)\n",
    "        self.loss_fn = detector_loss\n",
    "        self.metrics_fn = model_metrics\n",
    "    def call(self, inputs, targets=None, sample_weight=None):\n",
    "        loss = self.loss_fn(inputs[0], inputs[1]['logits'], model_config = model_config, valid_mask = inputs[2])\n",
    "        metrics = self.metrics_fn(inputs[0], inputs[1]['prob'], valid_mask = inputs[2])\n",
    "        self.add_loss(tf.math.reduce_mean(loss))\n",
    "        self.add_metric(metrics, name = 'precision')\n",
    "        return loss\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [1]\n",
    "\n",
    "def net(input_shape = (240, 320, 1)):\n",
    "    warped_images_inputs = Input(shape = input_shape, name = 'warped_images')\n",
    "    valid_masks_inputs = Input(shape = input_shape, name = 'valid_masks')\n",
    "    warped_points_inputs = Input(shape = input_shape, name = 'warped_points')\n",
    "    \n",
    "    encoder_output = shared_encoder(warped_images_inputs, model_config=model_config)\n",
    "    output = detector_head(encoder_output, model_config=model_config)\n",
    "    \n",
    "    loss_layer = DetectorLossLayer()([warped_points_inputs, output, valid_masks_inputs])\n",
    "    \n",
    "    model = keras.models.Model(inputs = [warped_images_inputs, valid_masks_inputs, warped_points_inputs] , \n",
    "                               outputs = [loss_layer])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net(input_shape = (240, 320, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "keras.utils.plot_model(model, to_file=\"model.png\", show_shapes=False, show_dtype=True, show_layer_names=True,\n",
    "    rankdir=\"TB\", expand_nested=False, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_loss(dummy_target, y_pred):\n",
    "    return tf.squeeze(y_pred)\n",
    "\n",
    "model.compile(optimizer = keras.optimizers.Adam(learning_rate = model_config['learning_rate']),\n",
    "              loss = dummy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = model_config['batch_size']\n",
    "\n",
    "train_image_path = DATA_PATH + '/anntrain2014'\n",
    "train_point_path = DATA_PATH + '/pointstrain2014'\n",
    "# train_homography_path = DATA_PATH + '/homographies_train'\n",
    "# train_warped_image_path = DATA_PATH + '/warptrain2014'\n",
    "# train_warped_point_path = DATA_PATH + '/warped_pointstrain2014'\n",
    "train_gen = DataGen(train_image_path, train_point_path, #train_homography_path, train_warped_image_path,\n",
    "#                     train_warped_point_path, \n",
    "                    batch_size = batch_size, is_training = True)\n",
    "\n",
    "val_image_path = DATA_PATH + '/annval2014'\n",
    "val_point_path = DATA_PATH + '/pointsval2014'\n",
    "# val_homography_path = DATA_PATH + '/homographies_val'\n",
    "# val_warped_image_path = DATA_PATH + '/warpval2014'\n",
    "# val_warped_point_path = DATA_PATH + '/warped_pointsval2014'\n",
    "val_gen = DataGen(val_image_path, val_point_path, #val_homography_path, val_warped_image_path,\n",
    "#                   val_warped_point_path, \n",
    "                  batch_size = batch_size, is_training = True)\n",
    "\n",
    "train_steps =  len(os.listdir(train_image_path))/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_gen , validation_data = val_gen, steps_per_epoch = train_steps, \n",
    "                    epochs = model_config['epochs'], callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('/root/Internship-Valeo/Project/results/checkpoint-magicpoint-coco-060322')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('/root/Internship-Valeo/Project/results/checkpoint-magicpoint-coco-050322')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_gen.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[0][31]*255, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[1][31], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[2][31],cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = val_gen.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[0][0]*255, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[1][0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[2][0],cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.reduce_mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = model.get_layer('tf.compat.v1.squeeze').output\n",
    "m = keras.models.Model(inputs = model.input, outputs = prob)\n",
    "\n",
    "y_pred = m.predict(x)\n",
    "\n",
    "if model_config['nms']:\n",
    "    prob = tf.map_fn(lambda p: box_nms(p, model_config['nms'],\n",
    "                                               min_prob=model_config['detection_threshold'],\n",
    "                                               keep_top_k=model_config['top_k']), y_pred)\n",
    "    pred = tf.cast(tf.greater_equal(prob, model_config['detection_threshold']), tf.float32)\n",
    "    \n",
    "# pred = pred * x[1] # multiplied with valid masks\n",
    "\n",
    "plt.imshow(pred[0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
