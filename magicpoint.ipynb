{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers as tfl\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow_addons.image import transform as H_transform\n",
    "import matplotlib.pyplot as plt\n",
    "import os, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/root/Internship-Valeo/Project/data'\n",
    "TMPDIR = '/root/Internship-Valeo/Project/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import synthetic_dataset\n",
    "from datasets.utils import pipeline\n",
    "from datasets.utils.pipeline import parse_primitives\n",
    "from datasets.utils import photometric_augmentation as photaug\n",
    "from models.homographies import (sample_homography, compute_valid_mask,\n",
    "                                            warp_points, filter_points)\n",
    "from models.utils import box_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "            'primitives': 'all',\n",
    "            'truncate': {'draw_ellipses': 0.3, 'draw_stripes': 0.2, 'gaussian_noise': 0.1},\n",
    "            'validation_size': 500,\n",
    "            'test_size': -1,\n",
    "            'on-the-fly': False,\n",
    "            'cache_in_memory': True,\n",
    "            'suffix': 'v6',\n",
    "            'add_augmentation_to_test_set': False, # set to true to evaluate with noise\n",
    "            'num_parallel_calls': 10,\n",
    "            'generation': {\n",
    "                'split_sizes': {'training': 10000, 'validation': 200, 'test': 500},\n",
    "                'image_size': [960, 1280],\n",
    "                'random_seed': 0,\n",
    "                'params': {\n",
    "                    'generate_background': {\n",
    "                        'min_kernel_size': 150, 'max_kernel_size': 500,\n",
    "                        'min_rad_ratio': 0.02, 'max_rad_ratio': 0.031},\n",
    "                    'draw_stripes': {'transform_params': (0.1, 0.1)},\n",
    "                    'draw_multiple_polygons': {'kernel_boundaries': (50, 100)}\n",
    "                },\n",
    "            },\n",
    "            'preprocessing': {\n",
    "#                 'resize': [240, 320],\n",
    "#                 'blur_size': 11,\n",
    "                'resize': [120, 160],\n",
    "                'blur_size': 21,\n",
    "            },\n",
    "            'augmentation': {\n",
    "                'photometric': {\n",
    "                    'enable': True,\n",
    "                    'primitives': ['random_brightness', 'random_contrast', 'additive_speckle_noise',\n",
    "                'additive_gaussian_noise', 'additive_shade', 'motion_blur'],\n",
    "                    'params': {\n",
    "                        'random_brightness': {'max_abs_change': 75},\n",
    "                        'random_contrast': {'strength_range': [0.3, 1.8]},\n",
    "                        'additive_gaussian_noise': {'stddev_range': [0, 15]},\n",
    "                        'additive_speckle_noise': {'prob_range': [0, 0.0035]},\n",
    "                        'additive_shade':{\n",
    "                            'transparency_range': [-0.5, 0.8],\n",
    "                            'kernel_size_range': [50, 100]},\n",
    "                        'motion_blur': {'max_kernel_size': 7}},\n",
    "                    'random_order': True,\n",
    "                },\n",
    "                'homographic': {\n",
    "                    'enable': True,\n",
    "                    'params': {\n",
    "                        'translation': True,\n",
    "                        'rotation': True,\n",
    "                        'scaling': True,\n",
    "                        'perspective': True,\n",
    "                        'scaling_amplitude': 0.2,\n",
    "                        'perspective_amplitude_x': 0.2,\n",
    "                        'perspective_amplitude_y': 0.2,\n",
    "                        'patch_ratio': 0.8,\n",
    "                        'max_angle': 1.57,  # 3.14\n",
    "                        'allow_artifacts': True,\n",
    "                        'translation_overflow': 0.05,\n",
    "                    },\n",
    "                    'valid_border_margin': 2,\n",
    "                },\n",
    "            }\n",
    "    }\n",
    "drawing_primitives = [\n",
    "            'draw_lines',\n",
    "            'draw_polygon',\n",
    "            'draw_multiple_polygons',\n",
    "            'draw_ellipses',\n",
    "            'draw_star',\n",
    "            'draw_checkerboard',\n",
    "            'draw_stripes',\n",
    "            'draw_cube',\n",
    "            'gaussian_noise'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs/scalars/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to run this again as synthetic shapes have been generated\n",
    "\n",
    "def dump_primitive_data(primitive, tar_path, config):\n",
    "    temp_dir = Path(TMPDIR, primitive)\n",
    "\n",
    "    synthetic_dataset.set_random_state(np.random.RandomState(\n",
    "                config['generation']['random_seed']))\n",
    "    for split, size in config['generation']['split_sizes'].items():\n",
    "        im_dir, pts_dir = [Path(temp_dir, i, split) for i in ['images', 'points']]\n",
    "        im_dir.mkdir(parents=True, exist_ok=True)\n",
    "        pts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for i in tqdm(range(size), desc=split, leave=False):\n",
    "            image = synthetic_dataset.generate_background(\n",
    "                        config['generation']['image_size'],\n",
    "                        config['generation']['params']['generate_background'])\n",
    "            points = np.array(getattr(synthetic_dataset, primitive)(\n",
    "                        image, config['generation']['params'].get(primitive, {})))\n",
    "            points = np.flip(points, 1)  # reverse convention with opencv\n",
    "\n",
    "            b = config['preprocessing']['blur_size']\n",
    "            image = cv2.GaussianBlur(image, (b, b), 0)\n",
    "            points = (points * np.array(config['preprocessing']['resize'], np.float)\n",
    "                          / np.array(config['generation']['image_size'], np.float))\n",
    "            image = cv2.resize(image, tuple(config['preprocessing']['resize'][::-1]),\n",
    "                                   interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            cv2.imwrite(str(Path(im_dir, '{}.png'.format(i))), image)\n",
    "            np.save(Path(pts_dir, '{}.npy'.format(i)), points)\n",
    "\n",
    "    # Pack into a tar file\n",
    "    tar = tarfile.open(tar_path, mode='w:gz')\n",
    "    tar.add(temp_dir, arcname=primitive)\n",
    "    tar.close()\n",
    "    shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primitives = parse_primitives(config['primitives'], drawing_primitives)\n",
    "basepath = Path(\n",
    "                DATA_PATH, 'synthetic_shapes' +\n",
    "                ('_{}'.format(config['suffix']) if config['suffix'] is not None else ''))\n",
    "basepath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "splits = {s: {'images': [], 'points': []}\n",
    "                  for s in ['training', 'validation', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to run this again as synthetic shapes have been generated\n",
    "\n",
    "# got an error here so reusing the previously dumped primitive data 25th Feb 2022\n",
    "\n",
    "for primitive in primitives:\n",
    "    tar_path = Path(basepath, '{}.tar.gz'.format(primitive))\n",
    "    if not tar_path.exists():\n",
    "        dump_primitive_data(primitive, tar_path, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for primitive in primitives:\n",
    "    # Untar locally\n",
    "    tar_path = Path(basepath, '{}.tar.gz'.format(primitive))\n",
    "    tar = tarfile.open(tar_path)\n",
    "    temp_dir = Path(TMPDIR)\n",
    "    tar.extractall(path=temp_dir)\n",
    "    tar.close()\n",
    "    # Gather filenames in all splits, optionally truncate\n",
    "    truncate = config['truncate'].get(primitive, 1)\n",
    "    path = Path(temp_dir, primitive)\n",
    "    for s in splits:\n",
    "        e = [str(p) for p in Path(path, 'images', s).iterdir()]\n",
    "        f = [p.replace('images', 'points') for p in e]\n",
    "        f = [p.replace('.png', '.npy') for p in f]\n",
    "        splits[s]['images'].extend(e[:int(truncate*len(e))])\n",
    "        splits[s]['points'].extend(f[:int(truncate*len(f))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "for s in splits:\n",
    "    perm = np.random.RandomState(0).permutation(len(splits[s]['images']))\n",
    "    for obj in ['images', 'points']:\n",
    "        splits[s][obj] = np.array(splits[s][obj])[perm].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(splits['training']['images']), len(splits['test']['images']), len(splits['validation']['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for photometric augmentation\n",
    "\n",
    "primitives_photo = parse_primitives(config['primitives'], photaug.augmentations)\n",
    "\n",
    "prim_configs = [config['augmentation']['photometric']['params'].get(p, {}) for p in primitives_photo]\n",
    "\n",
    "indices = tf.range(len(primitives_photo))\n",
    "if config['augmentation']['photometric']['random_order']:\n",
    "    indices = tf.random.shuffle(indices)\n",
    "def photo_aug_step(i, image):\n",
    "    fn_pairs = [(tf.equal(indices[i], j), lambda p=p, c=c: getattr(photaug, p)(image, **c))\n",
    "                for j, (p, c) in enumerate(zip(primitives_photo, prim_configs))]\n",
    "    image = tf.case(fn_pairs)\n",
    "    return i + 1, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gen_shape():\n",
    "    primitives = parse_primitives(config['primitives'], drawing_primitives)\n",
    "    while True:\n",
    "        primitive = np.random.choice(primitives)\n",
    "        image = synthetic_dataset.generate_background(\n",
    "                        config['generation']['image_size'],\n",
    "                        **config['generation']['params']['generate_background'])\n",
    "        points = np.array(getattr(synthetic_dataset, primitive)(\n",
    "                        image, **config['generation']['params'].get(primitive, {})))\n",
    "        yield (np.expand_dims(image, axis=-1).astype(np.float32),\n",
    "                       np.flip(points.astype(np.float32), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_image(filename):\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    return tf.cast(image, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read keypoints\n",
    "def _read_points(filename):\n",
    "    return np.load(filename).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['on-the-fly']:\n",
    "    data = tf.data.Dataset.from_generator(\n",
    "                    _gen_shape, (tf.float32, tf.float32),\n",
    "                    (tf.TensorShape(config['generation']['image_size']+[1]),\n",
    "                     tf.TensorShape([None, 2])))\n",
    "    data = data.map(lambda i, c: pipeline.downsample(\n",
    "                    i, c, **config['preprocessing']))\n",
    "else:\n",
    "    # Initialize dataset with file names\n",
    "    data = tf.data.Dataset.from_tensor_slices(\n",
    "                    (splits['training']['images'], splits['training']['points']))\n",
    "    # Read image and point coordinates\n",
    "    data = data.map(\n",
    "                    lambda image, points:\n",
    "                    (_read_image(image), tf.numpy_function(_read_points, [points], tf.float32)))\n",
    "    data = data.map(lambda image, points: (image, tf.reshape(points, [-1, 2])))\n",
    "\n",
    "# if split_name == 'validation':\n",
    "#     data = data.take(config['validation_size'])\n",
    "# elif split_name == 'test':\n",
    "#     data = data.take(config['test_size'])\n",
    "\n",
    "data = data.map(lambda image, kp: {'image': image, 'keypoints': kp})\n",
    "data = data.map(pipeline.add_dummy_valid_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['augmentation']['photometric']['enable']:\n",
    "    data = data.map(lambda d: pipeline.photometric_augmentation(d, **config['augmentation']['photometric']))\n",
    "if config['augmentation']['homographic']['enable']:\n",
    "    data = data.map(lambda d: pipeline.homographic_augmentation(\n",
    "                    d, **config['augmentation']['homographic']))\n",
    "\n",
    "# Convert the point coordinates to a dense keypoint map\n",
    "data = data.map(pipeline.add_keypoint_map)\n",
    "data = data.map(lambda d: {**d, 'image': tf.cast(d['image'], tf.float32) / 255.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['on-the-fly']:\n",
    "    val_data = tf.data.Dataset.from_generator(\n",
    "                    _gen_shape, (tf.float32, tf.float32),\n",
    "                    (tf.TensorShape(config['generation']['image_size']+[1]),\n",
    "                     tf.TensorShape([None, 2])))\n",
    "    val_data = val_data.map(lambda i, c: pipeline.downsample(\n",
    "                    i, c, **config['preprocessing']))\n",
    "else:\n",
    "    # Initialize dataset with file names\n",
    "    val_data = tf.data.Dataset.from_tensor_slices(\n",
    "                    (splits['validation']['images'], splits['validation']['points']))\n",
    "    # Read image and point coordinates\n",
    "    val_data = val_data.map(\n",
    "                    lambda image, points:\n",
    "                    (_read_image(image), tf.numpy_function(_read_points, [points], tf.float32)))\n",
    "    val_data = val_data.map(lambda image, points: (image, tf.reshape(points, [-1, 2])))\n",
    "\n",
    "val_data = val_data.map(lambda image, kp: {'image': image, 'keypoints': kp})\n",
    "val_data = val_data.map(pipeline.add_dummy_valid_mask)\n",
    "\n",
    "# Convert the point coordinates to a dense keypoint map\n",
    "val_data = val_data.map(pipeline.add_keypoint_map)\n",
    "val_data = val_data.map(lambda d: {**d, 'image': tf.cast(d['image'], tf.float32) / 255.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "            'data_format': 'channels_last',\n",
    "            'grid_size': 8,\n",
    "            'detection_threshold': 0.001, # 1/65\n",
    "            'descriptor_size': 256,\n",
    "            'batch_size': 64,\n",
    "            'eval_batch_size': 50,\n",
    "            'epochs': 50,\n",
    "            'learning_rate': 0.001,\n",
    "            'kernel_reg': 0.,\n",
    "            'lambda_d': 250,\n",
    "            'descriptor_size': 256,\n",
    "            'positive_margin': 1,\n",
    "            'negative_margin': 0.2,\n",
    "            'lambda_loss': 0.0001,\n",
    "            'nms': 4,\n",
    "            'top_k': 0,\n",
    "            'train_iter': 50000,\n",
    "            'eval_iter': 200,\n",
    "            'validation_interval': 1000,\n",
    "            'seed': 0,\n",
    "            #'save_interval': 5000,\n",
    "            #'keep_checkpoints': 20\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SyntheticShapes(keras.utils.Sequence):\n",
    "#     def __init__(self, image_files, point_files, is_training, batch_size = model_config['batch_size']):\n",
    "#         self.__image_files, self.__point_files = image_files, point_files\n",
    "#         self.__batch_size = batch_size\n",
    "#         self.__is_training = is_training\n",
    "#     def __getitem__(self, index):\n",
    "#         images = []\n",
    "#         points_maps = []\n",
    "#         points_list = []\n",
    "#         homography_list = [] # not returned yet\n",
    "#         warped_images = []\n",
    "#         valid_masks = []\n",
    "#         warped_points_list = []\n",
    "#         warped_points_maps = []\n",
    "        \n",
    "        \n",
    "#         if (index + 1)*self.__batch_size > len(self.__image_files):\n",
    "#             self.__batch_size = len(self.__image_files) - index * self.__batch_size\n",
    "            \n",
    "#         batch_img_files = self.__image_files[index * self.__batch_size:(index + 1) * self.__batch_size]\n",
    "#         batch_point_files = self.__point_files[index * self.__batch_size:(index + 1) * self.__batch_size]\n",
    "        \n",
    "#         for img_file, point_file, itr in zip(batch_img_files, batch_point_files, range(self.__batch_size)):\n",
    "\n",
    "#             image = cv2.imread(img_file, 0)\n",
    "#             image = np.expand_dims(image, axis = 2)\n",
    "#             image_shape = tf.shape(image)[:2]\n",
    "#             points = _read_points(point_file)\n",
    "#             points = np.round(points).astype(int)\n",
    "            \n",
    "#             if self.__is_training:\n",
    "#                 # add photometric_augmentation\n",
    "#                 _, image = tf.while_loop(lambda i, image: tf.less(i, len(primitives_photo)),\n",
    "#                                  photo_aug_step, [0, image], parallel_iterations=1)              \n",
    "                \n",
    "#                 # add homography\n",
    "#                 homography = sample_homography(image_shape, config['augmentation']['homographic']['params'])[0]\n",
    "#                 warped_image = H_transform(image, homography, interpolation='BILINEAR')\n",
    "#                 valid_mask = compute_valid_mask(image_shape, homography,\n",
    "#                                          config['augmentation']['homographic']['params']['valid_border_margin'])\n",
    "#                 warped_points = warp_points(points, homography)\n",
    "#                 warped_points = filter_points(warped_points, image_shape)\n",
    "#                 warped_points = np.round(warped_points).astype(int)\n",
    "                \n",
    "#                 warped_kp = tf.minimum(warped_points, image_shape-1)\n",
    "#                 warped_points_map = tf.scatter_nd(warped_kp, tf.ones([tf.shape(warped_kp)[0]], \n",
    "#                                                                      dtype=tf.int32), image_shape)\n",
    "                        \n",
    "#                 homography_list.append(homography)\n",
    "#                 warped_image = warped_image / 255.0\n",
    "#                 warped_images.append(warped_image)\n",
    "#                 valid_masks.append(valid_mask)\n",
    "#                 warped_points_list.append(warped_points)\n",
    "#                 warped_points_maps.append(warped_points_map)\n",
    "\n",
    "#             kp = tf.minimum(points, image_shape-1)\n",
    "#             points_map = tf.scatter_nd(kp, tf.ones([tf.shape(kp)[0]], dtype=tf.int32), image_shape)\n",
    "            \n",
    "#             image = image / 255.0\n",
    "#             images.append(image)\n",
    "#             points_maps.append(points_map)\n",
    "#             points_list.append(points)\n",
    "            \n",
    "            \n",
    "#         images = np.array(images)\n",
    "#         points_maps = np.expand_dims(points_maps, axis = 3)\n",
    "        \n",
    "#         if self.__is_training:\n",
    "#             warped_images = np.array(warped_images)\n",
    "#             warped_points_maps = np.expand_dims(warped_points_maps, axis = 3)\n",
    "#             valid_masks = np.array(valid_masks)\n",
    "#             dummy_loss_target = np.zeros(self.__batch_size)\n",
    "\n",
    "#             return [warped_images, valid_masks, warped_points_maps], [dummy_loss_target]\n",
    "        \n",
    "#         else:\n",
    "#             return images, points_maps   \n",
    "           \n",
    "#     def __len__(self):\n",
    "#         return int(np.ceil(len(self.__image_files) / float(self.__batch_size)))\n",
    "    \n",
    "#     def on_epoch_end(self):\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(inputs, filters, kernel_size, name, data_format, training=False,\n",
    "              batch_normalization=True, kernel_reg=0., **params):\n",
    "    x = tfl.Convolution2D(filters, kernel_size,\n",
    "                       kernel_regularizer=tf.keras.regularizers.L2(kernel_reg),\n",
    "                       data_format=data_format, **params)(inputs)\n",
    "    if batch_normalization:\n",
    "        x = tfl.BatchNormalization(\n",
    "                    fused=True,\n",
    "                    axis=1 if data_format == 'channels_first' else -1)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shared_encoder(inputs, model_config):\n",
    "    params_conv = {'padding': 'SAME', 'data_format': model_config['data_format'],\n",
    "                   'batch_normalization': True, 'activation': tf.nn.relu,\n",
    "                   'kernel_reg': model_config.get('kernel_reg', 0.)}\n",
    "    params_pool = {'padding': 'SAME', 'data_format': model_config['data_format']}\n",
    "    cfirst = model_config['data_format'] == 'channels_first'\n",
    "    cindex = 1 if cfirst else -1  # index of the channel\n",
    "    pool_size=(2, 2)\n",
    "    kernel = 3\n",
    "    # Encoder\n",
    "    conv1 = vgg_block(inputs, 64, (kernel, kernel), 'conv1_1', **params_conv)\n",
    "    conv2 = vgg_block(conv1, 64, (kernel, kernel), 'conv1_2', **params_conv)\n",
    "    pool1 = MaxPooling2D(pool_size, name=\"block1_pool\", **params_pool)(conv2)\n",
    "\n",
    "    conv3 = vgg_block(pool1, 64, (kernel, kernel), 'conv2_1', **params_conv)\n",
    "    conv4 = vgg_block(conv3, 64, (kernel, kernel), 'conv2_2', **params_conv)\n",
    "    pool2 = MaxPooling2D(pool_size, name=\"block2_pool\", **params_pool)(conv4)\n",
    "\n",
    "    conv5 = vgg_block(pool2, 128, (kernel, kernel), 'conv3_1', **params_conv)\n",
    "    conv6 = vgg_block(conv5, 128, (kernel, kernel), 'conv3_2', **params_conv)\n",
    "    pool3 = MaxPooling2D(pool_size, name=\"block3_pool\", **params_pool)(conv6)\n",
    "\n",
    "    conv7 = vgg_block(pool3, 128, (kernel, kernel), 'conv4_1', **params_conv)\n",
    "    conv8 = vgg_block(conv7, 128, (kernel, kernel), 'conv4_2', **params_conv)\n",
    "    return conv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detector_head(inputs, model_config):\n",
    "    params_conv = {'padding': 'SAME', 'data_format': model_config['data_format'],\n",
    "                   'batch_normalization': True,\n",
    "                   'kernel_reg': model_config.get('kernel_reg', 0.)}\n",
    "    cfirst = model_config['data_format'] == 'channels_first'\n",
    "    cindex = 1 if cfirst else -1  # index of the channel\n",
    "\n",
    "    x = vgg_block(inputs, 256, 3, 'conv1',\n",
    "                      activation=tf.nn.relu, **params_conv)\n",
    "    x = vgg_block(x, 1+pow(model_config['grid_size'], 2), 1, 'conv2',\n",
    "                      activation=None, **params_conv)\n",
    "\n",
    "    prob = tf.nn.softmax(x, axis=cindex)\n",
    "    # Strip the extra “no interest point” dustbin\n",
    "    prob = prob[:, :-1, :, :] if cfirst else prob[:, :, :, :-1]\n",
    "    prob = tf.nn.depth_to_space(\n",
    "              prob, model_config['grid_size'], data_format='NCHW' if cfirst else 'NHWC')\n",
    "    prob = tf.squeeze(prob, axis=cindex)\n",
    "    return {'logits': x, 'prob': prob}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detector_loss(keypoint_map, logits, model_config, valid_mask=None):\n",
    "    if model_config['data_format'] == 'channels_first':\n",
    "        logits = tf.transpose(logits, [0, 2, 3, 1])\n",
    "    # Convert the boolean labels to indices including the \"no interest point\" dustbin\n",
    "    labels = keypoint_map[..., tf.newaxis]  # for GPU\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    labels = tf.nn.space_to_depth(labels, model_config['grid_size'])\n",
    "    shape = tf.concat([tf.shape(labels)[:3], [1]], axis=0)\n",
    "    labels = tf.concat([2*labels, tf.ones(shape)], 3)\n",
    "    # Add a small random matrix to randomly break ties in argmax\n",
    "    labels = tf.argmax(labels + tf.random.uniform(tf.shape(labels), 0, 0.1), axis=3)\n",
    "    # Mask the pixels if bordering artifacts appear\n",
    "    valid_mask = tf.ones_like(keypoint_map) if valid_mask is None else valid_mask\n",
    "    valid_mask = valid_mask[..., tf.newaxis]  # for GPU\n",
    "    valid_mask = tf.cast(valid_mask, tf.float32)\n",
    "    valid_mask = tf.nn.space_to_depth(valid_mask, model_config['grid_size'])\n",
    "    valid_mask = tf.math.reduce_prod(valid_mask, axis=3)  # AND along the channel dim\n",
    "    valid_mask = tf.cast(valid_mask, tf.int64)\n",
    "#     labels = labels * valid_mask\n",
    "#     loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "    loss = tf.compat.v1.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits, weights=valid_mask)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_metrics(y_true, y_pred, valid_mask):\n",
    "    if model_config['nms']:\n",
    "        prob = tf.map_fn(lambda p: box_nms(p, model_config['nms'],\n",
    "                                               min_prob=model_config['detection_threshold'],\n",
    "                                               keep_top_k=model_config['top_k']), y_pred)\n",
    "    pred = tf.cast(tf.greater_equal(prob, model_config['detection_threshold']), tf.float32)\n",
    "#     pred = tf.expand_dims(pred, axis = 3)\n",
    "    pred = valid_mask * pred\n",
    "    labels = y_true\n",
    "    precision = tf.math.reduce_sum(pred * labels) / tf.math.reduce_sum(pred)\n",
    "    recall = tf.math.reduce_sum(pred * labels) / tf.math.reduce_sum(labels)\n",
    "    return {'precision': precision, 'recall': recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectorLossLayer(Layer):\n",
    "    def __init__(self, name='detector_loss_layer', trainable=False):\n",
    "        super(DetectorLossLayer, self).__init__(name=name)\n",
    "        self.loss_fn = detector_loss\n",
    "        self.metrics_fn = model_metrics\n",
    "    def call(self, inputs, targets=None, sample_weight=None):\n",
    "        loss = self.loss_fn(inputs[0], inputs[1]['logits'], model_config = model_config, valid_mask = inputs[2])\n",
    "        metrics = self.metrics_fn(inputs[0], inputs[1]['prob'], valid_mask = inputs[2])\n",
    "        self.add_loss(tf.math.reduce_mean(loss))\n",
    "        self.add_metric(metrics['precision'], name = 'precision')\n",
    "        self.add_metric(metrics['recall'], name = 'recall')\n",
    "        return loss\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [1]\n",
    "\n",
    "def net(input_shape1, input_shape2, input_shape3):\n",
    "    images_inputs = Input(shape = input_shape1, name = 'image')\n",
    "    valid_masks_inputs = Input(shape = input_shape2, name = 'valid_mask')\n",
    "    warped_points_inputs = Input(shape = input_shape3, name = 'keypoints')\n",
    "    \n",
    "    if model_config['data_format'] == 'channels_first':\n",
    "        images_inputs1 = tf.transpose(images_inputs, [0, 3, 1, 2])\n",
    "    \n",
    "    encoder_output = shared_encoder(images_inputs1, model_config=model_config)\n",
    "    output = detector_head(encoder_output, model_config=model_config)\n",
    "    \n",
    "    loss_layer = DetectorLossLayer()([warped_points_inputs, output, valid_masks_inputs])\n",
    "    \n",
    "    model = keras.models.Model(inputs = [images_inputs, valid_masks_inputs, warped_points_inputs] , \n",
    "                               outputs = [loss_layer])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net(input_shape1 = (120, 160, 1), input_shape2 = (120, 160), input_shape3 = (120, 160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "keras.utils.plot_model(model, to_file=\"model.png\", show_shapes=False, show_dtype=False, show_layer_names=True,\n",
    "    rankdir=\"TB\", expand_nested=False, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_loss(dummy_target, y_pred):\n",
    "    return tf.squeeze(y_pred)\n",
    "\n",
    "model.compile(optimizer = keras.optimizers.Adam(learning_rate = model_config['learning_rate']),\n",
    "              loss = dummy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = model_config['batch_size']\n",
    "\n",
    "# train_gen = SyntheticShapes(splits['training']['images'], splits['training']['points'], \n",
    "#                                            batch_size = batch_size, is_training = True)\n",
    "\n",
    "# val_gen = SyntheticShapes(splits['validation']['images'], splits['validation']['points'], \n",
    "#                                          batch_size = batch_size, is_training = True)\n",
    "\n",
    "# train_steps =  len(splits['training']['images'])/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.batch(model_config['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = val_data.take(config['validation_size'])\n",
    "val_data = val_data.batch(model_config['eval_batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(data , validation_data = val_data, #batch_size = model_config['batch_size'], \n",
    "                     #steps_per_epoch = 1000, \n",
    "                    epochs=model_config['epochs'], callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('/root/Internship-Valeo/Project/results/checkpoint-magicpoint-120x160-synth-aug-100322')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('/root/Internship-Valeo/Project/results/checkpoint-magicpoint-no_aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_gen.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x['image'][0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x['keypoints'][0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x['valid_mask'][0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['keypoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[0][0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[2][0],cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = SyntheticShapes(splits['test']['images'], splits['test']['points'], \n",
    "                           batch_size = model_config['batch_size'], is_training = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = test_gen.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[0][0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[1][0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[2][0],cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.reduce_mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = model.get_layer('tf.compat.v1.squeeze').output\n",
    "m = keras.models.Model(inputs = model.input, outputs = prob)\n",
    "\n",
    "y_pred = m.predict(x)\n",
    "\n",
    "if model_config['nms']:\n",
    "    prob = tf.map_fn(lambda p: box_nms(p, model_config['nms'],\n",
    "                                               min_prob=model_config['detection_threshold'],\n",
    "                                               keep_top_k=model_config['top_k']), y_pred)\n",
    "    pred = tf.cast(tf.greater_equal(prob, model_config['detection_threshold']), tf.float32)\n",
    "    \n",
    "# pred = pred * x[1] # multiplied with valid masks\n",
    "\n",
    "plt.imshow(pred[0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
