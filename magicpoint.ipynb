{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/usr/bin/python3 -m pip install --upgrade pip\n",
    "# !pip install opencv-python\n",
    "# !apt update\n",
    "# !apt install ffmpeg libsm6 libxext6  -y\n",
    "# !pip install tensorflow-addons\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers as tfl\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow_addons.image import transform as H_transform\n",
    "import matplotlib.pyplot as plt\n",
    "import os, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/Internship-Valeo/Project\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/root/Internship-Valeo/Project/data'\n",
    "TMPDIR = '/root/Internship-Valeo/Project/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import synthetic_dataset\n",
    "from datasets.utils import pipeline\n",
    "from datasets.utils.pipeline import parse_primitives\n",
    "from datasets.utils import photometric_augmentation as photaug\n",
    "from models.homographies import (sample_homography, compute_valid_mask,\n",
    "                                            warp_points, filter_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "            'primitives': 'all',\n",
    "            'truncate': {},\n",
    "            'validation_size': -1,\n",
    "            'test_size': -1,\n",
    "            'on-the-fly': False,\n",
    "            'cache_in_memory': False,\n",
    "            'suffix': None,\n",
    "            'add_augmentation_to_test_set': False,\n",
    "            'num_parallel_calls': 10,\n",
    "            'generation': {\n",
    "                'split_sizes': {'training': 10000, 'validation': 200, 'test': 500},\n",
    "                'image_size': [960, 1280],\n",
    "                'random_seed': 0,\n",
    "                'params': {\n",
    "                    'generate_background': {\n",
    "                        'min_kernel_size': 150, 'max_kernel_size': 500,\n",
    "                        'min_rad_ratio': 0.02, 'max_rad_ratio': 0.031},\n",
    "                    'draw_stripes': {'transform_params': (0.1, 0.1)},\n",
    "                    'draw_multiple_polygons': {'kernel_boundaries': (50, 100)}\n",
    "                },\n",
    "            },\n",
    "            'preprocessing': {\n",
    "                'resize': [240, 320],\n",
    "                'blur_size': 11,\n",
    "            },\n",
    "            'augmentation': {\n",
    "                'photometric': {\n",
    "                    'enable': False,\n",
    "                    'primitives': 'all',\n",
    "                    'params': {},\n",
    "                    'random_order': True,\n",
    "                },\n",
    "                'homographic': {\n",
    "                    'enable': True,\n",
    "                    'params': {\n",
    "                        'translation': True,\n",
    "                        'rotation': True,\n",
    "                        'scaling': True,\n",
    "                        'perspective': True,\n",
    "                        'scaling_amplitude': 0.2,\n",
    "                        'perspective_amplitude_x': 0.2,\n",
    "                        'perspective_amplitude_y': 0.2,\n",
    "                        'patch_ratio': 0.8,\n",
    "                        'max_angle': 1.57,  # 3.14\n",
    "                        'allow_artifacts': True,\n",
    "                        'translation_overflow': 0.05,\n",
    "                        'valid_border_margin': 2,\n",
    "                    },\n",
    "                    'valid_border_margin': 0,\n",
    "                },\n",
    "            }\n",
    "    }\n",
    "drawing_primitives = [\n",
    "            'draw_lines',\n",
    "            'draw_polygon',\n",
    "            'draw_multiple_polygons',\n",
    "            'draw_ellipses',\n",
    "            'draw_star',\n",
    "            'draw_checkerboard',\n",
    "            'draw_stripes',\n",
    "            'draw_cube',\n",
    "            'gaussian_noise'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs/scalars/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_primitive_data(primitive, tar_path, config):\n",
    "    temp_dir = Path(TMPDIR, primitive)\n",
    "\n",
    "    synthetic_dataset.set_random_state(np.random.RandomState(\n",
    "                config['generation']['random_seed']))\n",
    "    for split, size in config['generation']['split_sizes'].items():\n",
    "        im_dir, pts_dir = [Path(temp_dir, i, split) for i in ['images', 'points']]\n",
    "        im_dir.mkdir(parents=True, exist_ok=True)\n",
    "        pts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for i in tqdm(range(size), desc=split, leave=False):\n",
    "            image = synthetic_dataset.generate_background(\n",
    "                        config['generation']['image_size'],\n",
    "                        config['generation']['params']['generate_background'])\n",
    "            points = np.array(getattr(synthetic_dataset, primitive)(\n",
    "                        image, config['generation']['params'].get(primitive, {})))\n",
    "            points = np.flip(points, 1)  # reverse convention with opencv\n",
    "\n",
    "            b = config['preprocessing']['blur_size']\n",
    "            image = cv2.GaussianBlur(image, (b, b), 0)\n",
    "            points = (points * np.array(config['preprocessing']['resize'], np.float)\n",
    "                          / np.array(config['generation']['image_size'], np.float))\n",
    "            image = cv2.resize(image, tuple(config['preprocessing']['resize'][::-1]),\n",
    "                                   interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            cv2.imwrite(str(Path(im_dir, '{}.png'.format(i))), image)\n",
    "            np.save(Path(pts_dir, '{}.npy'.format(i)), points)\n",
    "\n",
    "    # Pack into a tar file\n",
    "    tar = tarfile.open(tar_path, mode='w:gz')\n",
    "    tar.add(temp_dir, arcname=primitive)\n",
    "    tar.close()\n",
    "    shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "primitives = parse_primitives(config['primitives'], drawing_primitives)\n",
    "basepath = Path(\n",
    "                DATA_PATH, 'synthetic_shapes' +\n",
    "                ('_{}'.format(config['suffix']) if config['suffix'] is not None else ''))\n",
    "basepath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "splits = {s: {'images': [], 'points': []}\n",
    "                  for s in ['training', 'validation', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for primitive in primitives:\n",
    "#     tar_path = Path(basepath, '{}.tar.gz'.format(primitive))\n",
    "#     if not tar_path.exists():\n",
    "#         dump_primitive_data(primitive, tar_path, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for primitive in primitives:\n",
    "    # Untar locally\n",
    "#     tar_path = Path(basepath, '{}.tar.gz'.format(primitive))\n",
    "#     tar = tarfile.open(tar_path)\n",
    "    temp_dir = Path(TMPDIR)\n",
    "#     tar.extractall(path=temp_dir)\n",
    "#     tar.close()\n",
    "    # Gather filenames in all splits, optionally truncate\n",
    "    truncate = config['truncate'].get(primitive, 1)\n",
    "    path = Path(temp_dir, primitive)\n",
    "    for s in splits:\n",
    "        e = [str(p) for p in Path(path, 'images', s).iterdir()]\n",
    "        f = [p.replace('images', 'points') for p in e]\n",
    "        f = [p.replace('.png', '.npy') for p in f]\n",
    "        splits[s]['images'].extend(e[:int(truncate*len(e))])\n",
    "        splits[s]['points'].extend(f[:int(truncate*len(f))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "for s in splits:\n",
    "    perm = np.random.RandomState(0).permutation(len(splits[s]['images']))\n",
    "    for obj in ['images', 'points']:\n",
    "        splits[s][obj] = np.array(splits[s][obj])[perm].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 4500, 1800)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits['training']['images']), len(splits['test']['images']), len(splits['validation']['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read keypoints\n",
    "def _read_points(filename):\n",
    "    return np.load(filename).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticShapes(keras.utils.Sequence):\n",
    "    def __init__(self, image_files, point_files, batch_size, is_training):\n",
    "        self.__image_files, self.__point_files = image_files, point_files\n",
    "        self.__batch_size = batch_size\n",
    "        self.__is_training = is_training\n",
    "    def __getitem__(self, index):\n",
    "        images = []\n",
    "        points_maps = []\n",
    "        points_list = []\n",
    "        \n",
    "        homography_list = []\n",
    "        warped_images = []\n",
    "        warped_mask_images = []   # not used yet\n",
    "        valid_masks = []\n",
    "        warped_points_list = []\n",
    "        warped_points_maps = []\n",
    "        \n",
    "        batch_img_files = self.__image_files[index * self.__batch_size:(index + 1) * self.__batch_size]\n",
    "        batch_point_files = self.__point_files[index * self.__batch_size:(index + 1) * self.__batch_size]\n",
    "        for img_file, point_file, itr in zip(batch_img_files, batch_point_files, range(self.__batch_size)):\n",
    "            image = cv2.imread(img_file, 0)\n",
    "            image = image / 255.0\n",
    "            image_shape = tf.shape(image)[:2]\n",
    "            points = _read_points(point_file)\n",
    "            points_map = np.zeros((image.shape[0],image.shape[1]))\n",
    "            points = np.round(points).astype(int)\n",
    "            warped_points_map = np.zeros((image.shape[0],image.shape[1]))\n",
    "            \n",
    "            if self.__is_training:\n",
    "                # add homography\n",
    "                homography = sample_homography(image_shape, config['augmentation']['homographic']['params'])[0]\n",
    "                warped_image = H_transform(image, homography, interpolation='BILINEAR')\n",
    "#                 warped_mask_image = H_transform(mask_image, homography, interpolation='NEAREST')\n",
    "                valid_mask = compute_valid_mask(image_shape, homography,\n",
    "                                         config['augmentation']['homographic']['valid_border_margin'])\n",
    "                warped_points = warp_points(points, homography)\n",
    "                warped_points = filter_points(warped_points, image_shape)\n",
    "                warped_points = np.round(warped_points).astype(int)\n",
    "                for i in range(len(warped_points)):\n",
    "                    # skip the points whose co-ordinates lie outside image shape\n",
    "                    # write better code for the following\n",
    "                    # better code written in superpoint official\n",
    "                    if not(warped_points[i][0] >= image.shape[0] or warped_points[i][1] >= image.shape[1]):\n",
    "                        warped_points_map[warped_points[i][0],warped_points[i][1]] = 1\n",
    "                        \n",
    "                homography_list.append(homography)\n",
    "                warped_images.append(warped_image)\n",
    "#                 warped_mask_images.append(warped_mask_image)\n",
    "                valid_masks.append(valid_mask)\n",
    "                warped_points_list.append(warped_points)\n",
    "                warped_points_maps.append(warped_points_map)\n",
    "\n",
    "                \n",
    "            for i in range(len(points)):\n",
    "                # skip the points whose co-ordinates lie outside image shape\n",
    "                # write better code for the following\n",
    "                # better code written in superpoint official\n",
    "                if not(points[i][0] >= image.shape[0] or points[i][1] >= image.shape[1]):\n",
    "                    points_map[points[i][0],points[i][1]] = 1\n",
    "                    \n",
    "            images.append(image)\n",
    "            points_maps.append(points_map)\n",
    "            points_list.append(points)\n",
    "            \n",
    "\n",
    "            \n",
    "        images = np.array(images)\n",
    "        points_maps = np.expand_dims(points_maps, axis = 3)\n",
    "        \n",
    "        if self.__is_training:\n",
    "            warped_images = np.array(warped_images)\n",
    "            warped_points_maps = np.expand_dims(warped_points_maps, axis = 3)\n",
    "            return warped_images, warped_points_maps\n",
    "        \n",
    "        else:\n",
    "            return images, points_maps\n",
    "        \n",
    "#         return (images, points_maps, points_list, homography_list, warped_images, \n",
    "#                 warped_mask_images, valid_masks, warped_points_list, warped_points_maps)\n",
    "\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.__image_files) / float(self.__batch_size)))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        mydir = os.path.join(os.getcwd(), 'results')\n",
    "        mydir = os.path.join(mydir, datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "        os.makedirs(mydir)\n",
    "        model.save(mydir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         data = data.map(lambda image, kp: {'image': image, 'keypoints': kp})\n",
    "#         data = data.map(pipeline.add_dummy_valid_mask)\n",
    "\n",
    "#         # Apply augmentation\n",
    "#         if split_name == 'training' or config['add_augmentation_to_test_set']:\n",
    "#             if config['augmentation']['photometric']['enable']:\n",
    "#                 data = data.map_parallel(lambda d: pipeline.photometric_augmentation(\n",
    "#                     d, **config['augmentation']['photometric']))\n",
    "#             if config['augmentation']['homographic']['enable']:\n",
    "#                 data = data.map_parallel(lambda d: pipeline.homographic_augmentation(\n",
    "#                     d, **config['augmentation']['homographic']))\n",
    "\n",
    "#         # Convert the point coordinates to a dense keypoint map\n",
    "#         data = data.map_parallel(pipeline.add_keypoint_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "            'data_format': 'channels_last',\n",
    "            'grid_size': 8,\n",
    "            'detection_threshold': 0.4,\n",
    "            'descriptor_size': 256,\n",
    "#             'batch_size': 32,\n",
    "            'learning_rate': 0.001,\n",
    "            'lambda_d': 250,\n",
    "            'descriptor_size': 256,\n",
    "            'positive_margin': 1,\n",
    "            'negative_margin': 0.2,\n",
    "            'lambda_loss': 0.0001,\n",
    "            'nms': 0,\n",
    "            'top_k': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(inputs, filters, kernel_size, name, data_format, training=False,\n",
    "              batch_normalization=True, kernel_reg=0., **params):\n",
    "    x = tfl.Convolution2D(filters, kernel_size, kernel_initializer='he_uniform',\n",
    "                       kernel_regularizer=tf.keras.regularizers.L2(kernel_reg),\n",
    "                       data_format=data_format, **params)(inputs)\n",
    "    if batch_normalization:\n",
    "        x = tfl.BatchNormalization(\n",
    "                    fused=True,\n",
    "                    axis=1 if data_format == 'channels_first' else -1)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shared_encoder(inputs, model_config):\n",
    "    params_conv = {'padding': 'SAME', 'data_format': model_config['data_format'],\n",
    "                   'batch_normalization': True,\n",
    "                   'kernel_reg': model_config.get('kernel_reg', 0.)}\n",
    "    cfirst = model_config['data_format'] == 'channels_first'\n",
    "    cindex = 1 if cfirst else -1  # index of the channel\n",
    "    pool_size=(2, 2)\n",
    "    kernel = 3\n",
    "    # Encoder\n",
    "    conv1 = vgg_block(inputs, 64, (kernel, kernel), 'conv1_1', **params_conv)\n",
    "    conv2 = vgg_block(conv1, 64, (kernel, kernel), 'conv1_2', **params_conv)\n",
    "    pool1 = MaxPooling2D(pool_size, name=\"block1_pool\")(conv2)\n",
    "\n",
    "    conv3 = vgg_block(pool1, 64, (kernel, kernel), 'conv2_1', **params_conv)\n",
    "    conv4 = vgg_block(conv3, 64, (kernel, kernel), 'conv2_2', **params_conv)\n",
    "    pool2 = MaxPooling2D(pool_size, name=\"block2_pool\")(conv4)\n",
    "\n",
    "    conv5 = vgg_block(pool2, 128, (kernel, kernel), 'conv3_1', **params_conv)\n",
    "    conv6 = vgg_block(conv5, 128, (kernel, kernel), 'conv3_2', **params_conv)\n",
    "    pool3 = MaxPooling2D(pool_size, name=\"block3_pool\")(conv6)\n",
    "\n",
    "    conv7 = vgg_block(pool3, 128, (kernel, kernel), 'conv4_1', **params_conv)\n",
    "    conv8 = vgg_block(conv7, 128, (kernel, kernel), 'conv4_2', **params_conv)\n",
    "    return conv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detector_head(inputs, model_config):\n",
    "    params_conv = {'padding': 'SAME', 'data_format': model_config['data_format'],\n",
    "                   'batch_normalization': True,\n",
    "                   'kernel_reg': model_config.get('kernel_reg', 0.)}\n",
    "#     cfirst = model_config['data_format'] == 'channels_first'\n",
    "#     cindex = 1 if cfirst else -1  # index of the channel\n",
    "\n",
    "\n",
    "    x = vgg_block(inputs, 256, 3, 'conv1',\n",
    "                      activation=tf.nn.relu, **params_conv)\n",
    "    x = vgg_block(x, 1+pow(model_config['grid_size'], 2), 1, 'conv2',\n",
    "                      activation=None, **params_conv)\n",
    "\n",
    "#     prob = tf.nn.softmax(x, axis=cindex)\n",
    "#     # Strip the extra “no interest point” dustbin\n",
    "#     prob = prob[:, :-1, :, :] if cfirst else prob[:, :, :, :-1]\n",
    "#     prob = tf.nn.depth_to_space(\n",
    "#               prob, model_config['grid_size'], data_format='NCHW' if cfirst else 'NHWC')\n",
    "#     prob = tf.squeeze(prob, axis=cindex)\n",
    "#     return {'logits': x, 'prob': prob}\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(input_shape = (240, 320, 1)):\n",
    "    inputs = Input(shape = input_shape)\n",
    "    encoder_output = shared_encoder(inputs, model_config=model_config)\n",
    "    output = detector_head(encoder_output, model_config=model_config)\n",
    "    model = keras.models.Model(inputs = inputs , outputs = output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net(input_shape = (240, 320, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detector_loss(keypoint_map, logits, model_config, valid_mask=None):\n",
    "    if model_config['data_format'] == 'channels_first':\n",
    "        logits = tf.transpose(logits, [0, 2, 3, 1])\n",
    "    # Convert the boolean labels to indices including the \"no interest point\" dustbin\n",
    "    labels = keypoint_map#[..., tf.newaxis]  # for GPU\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    labels = tf.nn.space_to_depth(labels, model_config['grid_size'])\n",
    "    shape = tf.concat([tf.shape(labels)[:3], [1]], axis=0)\n",
    "    labels = tf.concat([2*labels, tf.ones(shape)], 3)\n",
    "    # Add a small random matrix to randomly break ties in argmax\n",
    "    labels = tf.argmax(labels + tf.random.uniform(tf.shape(labels), 0, 0.1), axis=3)\n",
    "    # Mask the pixels if bordering artifacts appear\n",
    "#     valid_mask = tf.ones_like(keypoint_map) if valid_mask is None else valid_mask\n",
    "#     valid_mask = valid_mask[..., tf.newaxis]  # for GPU\n",
    "#     valid_mask = tf.cast(valid_mask, tf.float32)\n",
    "#     valid_mask = tf.nn.space_to_depth(valid_mask, model_config['grid_size'])\n",
    "#     valid_mask = tf.math.reduce_prod(valid_mask, axis=3)  # AND along the channel dim\n",
    " \n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "    return loss\n",
    "\n",
    "def wrapper_fn(model_config):\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        return detector_loss(y_true, y_pred, model_config=model_config)\n",
    "#                              valid_mask=inputs['valid_mask'])\n",
    "    return loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_metrics(y_true, y_pred):\n",
    "    cfirst = model_config['data_format'] == 'channels_first'\n",
    "    cindex = 1 if cfirst else -1  # index of the channel\n",
    "\n",
    "    y_pred = tf.nn.softmax(y_pred, axis=cindex)\n",
    "    y_pred = tf.argmax(y_pred, axis =cindex)\n",
    "  \n",
    "    y_pred = tf.one_hot(y_pred, depth = 1+pow(model_config['grid_size'], 2))\n",
    "  \n",
    "    y_true = tf.nn.space_to_depth(y_true, model_config['grid_size'])\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    # Strip the extra “no interest point” dustbin\n",
    "    y_pred = y_pred[:, :-1, :, :] if cfirst else y_pred[:, :, :, :-1]\n",
    "   \n",
    "    precision = tf.math.reduce_sum(y_pred * y_true) /tf.math.reduce_sum(y_pred)\n",
    "    recall = tf.math.reduce_sum(y_pred * y_true) / tf.math.reduce_sum(y_true)\n",
    "#     return {'precision': precision, 'recall': recall}\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss = wrapper_fn(model_config=model_config)\n",
    "model.compile(optimizer = keras.optimizers.Adam(learning_rate = 1e-3),\n",
    "              loss = model_loss, metrics = [model_metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "  93/1406 [>.............................] - ETA: 19:01 - loss: 4.0618 - model_metrics: 4.5046e-04"
     ]
    }
   ],
   "source": [
    "# train_images, train_points_maps, train_points_list, train_homography_list, train_warped_images,\n",
    "# train_warped_mask_images, train_valid_masks, train_warped_points_list, \n",
    "# train_warped_points_maps \n",
    "\n",
    "train_gen = SyntheticShapes(splits['training']['images'], splits['training']['points'], \n",
    "                                           batch_size = batch_size, is_training = False)\n",
    "\n",
    "# val_images, val_points_maps, val_points_list, val_homography_list, val_warped_images, val_warped_mask_images, \n",
    "# val_valid_masks, val_warped_points_list, \n",
    "# val_warped_points_maps \n",
    "\n",
    "val_gen = SyntheticShapes(splits['validation']['images'], splits['validation']['points'], \n",
    "                                         batch_size = batch_size, is_training = False)\n",
    "\n",
    "train_steps =  len(splits['training']['images'])/batch_size\n",
    "\n",
    "history = model.fit(train_gen , validation_data = val_gen, steps_per_epoch = train_steps, epochs=epochs,\n",
    "                   callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['model_metrics'])\n",
    "plt.plot(history.history['val_model_metrics'])\n",
    "plt.title('model precision')\n",
    "plt.ylabel('precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_gen.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y[0],cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = SyntheticShapes(splits['test']['images'], splits['test']['points'], batch_size = batch_size, is_training = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = test_gen.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[1], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y[1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfirst = model_config['data_format'] == 'channels_first'\n",
    "cindex = 1 if cfirst else -1  # index of the channel\n",
    "labels = tf.argmax(result, axis =cindex)\n",
    "one_hot = tf.one_hot(labels, depth = 1+pow(model_config['grid_size'], 2))\n",
    "# Strip the extra “no interest point” dustbin\n",
    "one_hot = one_hot[:, :-1, :, :] if cfirst else one_hot[:, :, :, :-1]\n",
    "one_hot = tf.nn.depth_to_space(\n",
    "              one_hot, model_config['grid_size'], data_format='NCHW' if cfirst else 'NHWC')\n",
    "one_hot = tf.squeeze(one_hot, axis=cindex)\n",
    "\n",
    "plt.imshow((one_hot)[0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics(y, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
