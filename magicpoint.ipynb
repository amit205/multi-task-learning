{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/usr/bin/python3 -m pip install --upgrade pip\n",
    "# !pip install opencv-python\n",
    "# !apt update\n",
    "# !apt install ffmpeg libsm6 libxext6  -y\n",
    "# !pip install tensorflow-addons\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers as tfl\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/Internship-Valeo/Project\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/root/Internship-Valeo/Project/data'\n",
    "TMPDIR = '/root/Internship-Valeo/Project/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import synthetic_dataset\n",
    "from datasets.utils import pipeline\n",
    "from datasets.utils.pipeline import parse_primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "            'primitives': 'all',\n",
    "            'truncate': {},\n",
    "            'validation_size': -1,\n",
    "            'test_size': -1,\n",
    "            'on-the-fly': False,\n",
    "            'cache_in_memory': False,\n",
    "            'suffix': None,\n",
    "            'add_augmentation_to_test_set': False,\n",
    "            'num_parallel_calls': 10,\n",
    "            'generation': {\n",
    "                'split_sizes': {'training': 10000, 'validation': 200, 'test': 500},\n",
    "                'image_size': [960, 1280],\n",
    "                'random_seed': 0,\n",
    "                'params': {\n",
    "                    'generate_background': {\n",
    "                        'min_kernel_size': 150, 'max_kernel_size': 500,\n",
    "                        'min_rad_ratio': 0.02, 'max_rad_ratio': 0.031},\n",
    "                    'draw_stripes': {'transform_params': (0.1, 0.1)},\n",
    "                    'draw_multiple_polygons': {'kernel_boundaries': (50, 100)}\n",
    "                },\n",
    "            },\n",
    "            'preprocessing': {\n",
    "                'resize': [240, 320],\n",
    "                'blur_size': 11,\n",
    "            },\n",
    "            'augmentation': {\n",
    "                'photometric': {\n",
    "                    'enable': False,\n",
    "                    'primitives': 'all',\n",
    "                    'params': {},\n",
    "                    'random_order': True,\n",
    "                },\n",
    "                'homographic': {\n",
    "                    'enable': False,\n",
    "                    'params': {},\n",
    "                    'valid_border_margin': 0,\n",
    "                },\n",
    "            }\n",
    "    }\n",
    "drawing_primitives = [\n",
    "            'draw_lines',\n",
    "            'draw_polygon',\n",
    "            'draw_multiple_polygons',\n",
    "            'draw_ellipses',\n",
    "            'draw_star',\n",
    "            'draw_checkerboard',\n",
    "            'draw_stripes',\n",
    "            'draw_cube',\n",
    "            'gaussian_noise'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_primitive_data(primitive, tar_path, config):\n",
    "    temp_dir = Path(TMPDIR, primitive)\n",
    "\n",
    "    synthetic_dataset.set_random_state(np.random.RandomState(\n",
    "                config['generation']['random_seed']))\n",
    "    for split, size in config['generation']['split_sizes'].items():\n",
    "        im_dir, pts_dir = [Path(temp_dir, i, split) for i in ['images', 'points']]\n",
    "        im_dir.mkdir(parents=True, exist_ok=True)\n",
    "        pts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for i in tqdm(range(size), desc=split, leave=False):\n",
    "            image = synthetic_dataset.generate_background(\n",
    "                        config['generation']['image_size'],\n",
    "                        config['generation']['params']['generate_background'])\n",
    "            points = np.array(getattr(synthetic_dataset, primitive)(\n",
    "                        image, config['generation']['params'].get(primitive, {})))\n",
    "            points = np.flip(points, 1)  # reverse convention with opencv\n",
    "\n",
    "            b = config['preprocessing']['blur_size']\n",
    "            image = cv2.GaussianBlur(image, (b, b), 0)\n",
    "            points = (points * np.array(config['preprocessing']['resize'], np.float)\n",
    "                          / np.array(config['generation']['image_size'], np.float))\n",
    "            image = cv2.resize(image, tuple(config['preprocessing']['resize'][::-1]),\n",
    "                                   interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            cv2.imwrite(str(Path(im_dir, '{}.png'.format(i))), image)\n",
    "            np.save(Path(pts_dir, '{}.npy'.format(i)), points)\n",
    "\n",
    "    # Pack into a tar file\n",
    "    tar = tarfile.open(tar_path, mode='w:gz')\n",
    "    tar.add(temp_dir, arcname=primitive)\n",
    "    tar.close()\n",
    "    shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "primitives = parse_primitives(config['primitives'], drawing_primitives)\n",
    "basepath = Path(\n",
    "                DATA_PATH, 'synthetic_shapes' +\n",
    "                ('_{}'.format(config['suffix']) if config['suffix'] is not None else ''))\n",
    "basepath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "splits = {s: {'images': [], 'points': []}\n",
    "                  for s in ['training', 'validation', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for primitive in primitives:\n",
    "#     tar_path = Path(basepath, '{}.tar.gz'.format(primitive))\n",
    "#     if not tar_path.exists():\n",
    "#         dump_primitive_data(primitive, tar_path, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for primitive in primitives:\n",
    "    # Untar locally\n",
    "#     tar_path = Path(basepath, '{}.tar.gz'.format(primitive))\n",
    "#     tar = tarfile.open(tar_path)\n",
    "    temp_dir = Path(TMPDIR)\n",
    "#     tar.extractall(path=temp_dir)\n",
    "#     tar.close()\n",
    "    # Gather filenames in all splits, optionally truncate\n",
    "    truncate = config['truncate'].get(primitive, 1)\n",
    "    path = Path(temp_dir, primitive)\n",
    "    for s in splits:\n",
    "        e = [str(p) for p in Path(path, 'images', s).iterdir()]\n",
    "        f = [p.replace('images', 'points') for p in e]\n",
    "        f = [p.replace('.png', '.npy') for p in f]\n",
    "        splits[s]['images'].extend(e[:int(truncate*len(e))])\n",
    "        splits[s]['points'].extend(f[:int(truncate*len(f))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "for s in splits:\n",
    "    perm = np.random.RandomState(0).permutation(len(splits[s]['images']))\n",
    "    for obj in ['images', 'points']:\n",
    "        splits[s][obj] = np.array(splits[s][obj])[perm].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 4500, 1800)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits['training']['images']), len(splits['test']['images']), len(splits['validation']['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read keypoints\n",
    "def _read_points(filename):\n",
    "    return np.load(filename).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticShapes(keras.utils.Sequence):\n",
    "    def __init__(self, image_files, point_files, batch_size =8):\n",
    "        self.__image_files, self.__point_files = image_files, point_files\n",
    "        self.__batch_size = batch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        images = []\n",
    "        points_maps = []\n",
    "        batch_img_files = self.__image_files[index * self.__batch_size:(index + 1) * self.__batch_size]\n",
    "        batch_point_files = self.__point_files[index * self.__batch_size:(index + 1) * self.__batch_size]\n",
    "        for img_file, point_file, itr in zip(batch_img_files, batch_point_files, range(self.__batch_size)):\n",
    "#             print(img_file)\n",
    "#             print(point_file)\n",
    "            image = cv2.imread(img_file, 0)\n",
    "            image = image / 255.0\n",
    "            points = _read_points(point_file)\n",
    "            points_map = np.zeros((image.shape[0],image.shape[1]))\n",
    "            points = np.round(points).astype(int)\n",
    "            for i in range(len(points)):\n",
    "                # skip the points whose co-ordinates lie outside image shape\n",
    "                if not(points[i][0] >= image.shape[0] or points[i][1] >= image.shape[1]):\n",
    "                    points_map[points[i][0],points[i][1]] = 1\n",
    "            images.append(image)\n",
    "            points_maps.append(points_map)\n",
    "            \n",
    "#         images = np.asarray(images).astype(np.float32)\n",
    "        images = np.array(images)\n",
    "        points_maps = np.array(points_maps)\n",
    "#         points_maps = np.asarray(points_maps).astype(np.float32)\n",
    "\n",
    "        return images, points_maps\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.__image_files) / float(self.__batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         data = data.map(lambda image, kp: {'image': image, 'keypoints': kp})\n",
    "#         data = data.map(pipeline.add_dummy_valid_mask)\n",
    "\n",
    "#         # Apply augmentation\n",
    "#         if split_name == 'training' or config['add_augmentation_to_test_set']:\n",
    "#             if config['augmentation']['photometric']['enable']:\n",
    "#                 data = data.map_parallel(lambda d: pipeline.photometric_augmentation(\n",
    "#                     d, **config['augmentation']['photometric']))\n",
    "#             if config['augmentation']['homographic']['enable']:\n",
    "#                 data = data.map_parallel(lambda d: pipeline.homographic_augmentation(\n",
    "#                     d, **config['augmentation']['homographic']))\n",
    "\n",
    "#         # Convert the point coordinates to a dense keypoint map\n",
    "#         data = data.map_parallel(pipeline.add_keypoint_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "            'data_format': 'channels_last',\n",
    "            'grid_size': 8,\n",
    "            'detection_threshold': 0.4,\n",
    "            'descriptor_size': 256,\n",
    "            'batch_size': 32,\n",
    "            'learning_rate': 0.001,\n",
    "            'lambda_d': 250,\n",
    "            'descriptor_size': 256,\n",
    "            'positive_margin': 1,\n",
    "            'negative_margin': 0.2,\n",
    "            'lambda_loss': 0.0001,\n",
    "            'nms': 0,\n",
    "            'top_k': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(inputs, filters, kernel_size, name, data_format, training=False,\n",
    "              batch_normalization=True, kernel_reg=0., **params):\n",
    "    x = tfl.Convolution2D(filters, kernel_size, kernel_initializer='he_uniform',\n",
    "                       kernel_regularizer=tf.keras.regularizers.L2(kernel_reg),\n",
    "                       data_format=data_format, **params)(inputs)\n",
    "    if batch_normalization:\n",
    "        x = tfl.BatchNormalization(\n",
    "                    fused=True,\n",
    "                    axis=1 if data_format == 'channels_first' else -1)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shared_encoder(inputs, model_config):\n",
    "    params_conv = {'padding': 'SAME', 'data_format': model_config['data_format'],\n",
    "                   'batch_normalization': True,\n",
    "                   'kernel_reg': model_config.get('kernel_reg', 0.)}\n",
    "    cfirst = model_config['data_format'] == 'channels_first'\n",
    "    cindex = 1 if cfirst else -1  # index of the channel\n",
    "    pool_size=(2, 2)\n",
    "    kernel = 3\n",
    "    # Encoder\n",
    "    conv1 = vgg_block(inputs, 64, (kernel, kernel), 'conv1_1', **params_conv)\n",
    "    conv2 = vgg_block(conv1, 64, (kernel, kernel), 'conv1_2', **params_conv)\n",
    "    pool1 = MaxPooling2D(pool_size, name=\"block1_pool\")(conv2)\n",
    "\n",
    "    conv3 = vgg_block(pool1, 64, (kernel, kernel), 'conv2_1', **params_conv)\n",
    "    conv4 = vgg_block(conv3, 64, (kernel, kernel), 'conv2_2', **params_conv)\n",
    "    pool2 = MaxPooling2D(pool_size, name=\"block2_pool\")(conv4)\n",
    "\n",
    "    conv5 = vgg_block(pool2, 128, (kernel, kernel), 'conv3_1', **params_conv)\n",
    "    conv6 = vgg_block(conv5, 128, (kernel, kernel), 'conv3_2', **params_conv)\n",
    "    pool3 = MaxPooling2D(pool_size, name=\"block3_pool\")(conv6)\n",
    "\n",
    "    conv7 = vgg_block(pool3, 128, (kernel, kernel), 'conv4_1', **params_conv)\n",
    "    conv8 = vgg_block(conv7, 128, (kernel, kernel), 'conv4_2', **params_conv)\n",
    "    return conv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detector_head(inputs, model_config):\n",
    "    params_conv = {'padding': 'SAME', 'data_format': model_config['data_format'],\n",
    "                   'batch_normalization': True,\n",
    "                   'kernel_reg': model_config.get('kernel_reg', 0.)}\n",
    "    cfirst = model_config['data_format'] == 'channels_first'\n",
    "    cindex = 1 if cfirst else -1  # index of the channel\n",
    "\n",
    "\n",
    "    x = vgg_block(inputs, 256, 3, 'conv1',\n",
    "                      activation=tf.nn.relu, **params_conv)\n",
    "    x = vgg_block(x, 1+pow(model_config['grid_size'], 2), 1, 'conv2',\n",
    "                      activation=None, **params_conv)\n",
    "    \n",
    "    prob = Activation('sigmoid')(x)\n",
    "\n",
    "#     prob = tf.nn.softmax(x, axis=cindex)\n",
    "    # Strip the extra “no interest point” dustbin\n",
    "    prob = prob[:, :-1, :, :] if cfirst else prob[:, :, :, :-1]\n",
    "    prob = tf.nn.depth_to_space(\n",
    "              prob, model_config['grid_size'], data_format='NCHW' if cfirst else 'NHWC')\n",
    "    prob = tf.squeeze(prob, axis=cindex)\n",
    "#     return {'logits': x, 'prob': prob}\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(input_shape = (240, 320, 1)):\n",
    "    inputs = Input(shape = input_shape)\n",
    "    encoder_output = shared_encoder(inputs, model_config)\n",
    "    output = detector_head(encoder_output, model_config)\n",
    "    model = keras.models.Model(inputs = inputs , outputs = output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net(input_shape = (240, 320, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 240, 320, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 240, 320, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 240, 320, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 240, 320, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 240, 320, 64)      256       \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 60, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 60, 80, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 60, 80, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 60, 80, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 60, 80, 128)       512       \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 30, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 40, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 30, 40, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 40, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 40, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 30, 40, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 30, 40, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 30, 40, 65)        16705     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 30, 40, 65)        260       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 30, 40, 65)        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem (Sl (None, 30, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "tf.nn.depth_to_space (TFOpLa (None, 240, 320, 1)       0         \n",
      "_________________________________________________________________\n",
      "tf.compat.v1.squeeze (TFOpLa (None, 240, 320)          0         \n",
      "=================================================================\n",
      "Total params: 944,261\n",
      "Trainable params: 942,083\n",
      "Non-trainable params: 2,178\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detector_loss(keypoint_map, logits, model_config, valid_mask=None):\n",
    "#     # Convert the boolean labels to indices including the \"no interest point\" dustbin\n",
    "#     labels = tf.to_float(keypoint_map[..., tf.newaxis])  # for GPU\n",
    "#     labels = tf.nn.space_to_depth(labels, model_config['grid_size'])\n",
    "#     shape = tf.concat([tf.shape(labels)[:3], [1]], axis=0)\n",
    "#     labels = tf.concat([2*labels, tf.ones(shape)], 3)\n",
    "#     # Add a small random matrix to randomly break ties in argmax\n",
    "#     labels = tf.argmax(labels + tf.random_uniform(tf.shape(labels), 0, 0.1),\n",
    "#                        axis=3)\n",
    "\n",
    "#     # Mask the pixels if bordering artifacts appear\n",
    "#     valid_mask = tf.ones_like(keypoint_map) if valid_mask is None else valid_mask\n",
    "#     valid_mask = tf.to_float(valid_mask[..., tf.newaxis])  # for GPU\n",
    "#     valid_mask = tf.space_to_depth(valid_mask, model_config['grid_size'])\n",
    "#     valid_mask = tf.reduce_prod(valid_mask, axis=3)  # AND along the channel dim\n",
    "\n",
    "#     loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "#             labels=labels, logits=logits, weights=valid_mask)\n",
    "#     return loss\n",
    "\n",
    "# def loss_fn(outputs, inputs, model_config=model_config):\n",
    "#     if model_config['data_format'] == 'channels_first':\n",
    "#         outputs['logits'] = tf.transpose(outputs['logits'], [0, 2, 3, 1])\n",
    "#         return detector_loss(inputs['keypoint_map'], outputs['logits'],model_config=model_config,\n",
    "#                              valid_mask=inputs['valid_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = keras.optimizers.Adam(learning_rate = 1e-4),\n",
    "              loss = tf.nn.softmax_cross_entropy_with_logits, metrics = ['Precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 413/1406 [=======>......................] - ETA: 25:21 - loss: 0.1861 - precision: 6.0637e-04"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "train_gen = SyntheticShapes(splits['training']['images'], splits['training']['points'], batch_size = batch_size)\n",
    "val_gen = SyntheticShapes(splits['validation']['images'], splits['validation']['points'], batch_size = batch_size)\n",
    "\n",
    "train_steps =  len(splits['training']['images'])/batch_size\n",
    "\n",
    "model.fit(train_gen , validation_data = val_gen, steps_per_epoch = train_steps, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_gen.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
